{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1d00e7c-47c9-4d7c-a394-d7c73a175e5f",
   "metadata": {
    "name": "cell1"
   },
   "source": [
    "# Train a Latent Dirichlet Allocation (LDA) Topic Model\n",
    "\n",
    "This notebook trains an LDA model for predicting the latent topics in customer comments.\n",
    "\n",
    "## Notebook Summary\n",
    "\n",
    "**It takes as inputs...**\n",
    "\n",
    "2. A range of standard packages for modelling and evaluation\n",
    "3. A custom py script for preparing the data\n",
    "\n",
    "\n",
    "**It applies the following process...**\n",
    "\n",
    "1. Data preperation\n",
    "2. Model evaluation\n",
    "3. Model selection (confirmed by the user)\n",
    "4. Export model to be used for latent topic predictions\n",
    "\n",
    "**It's outputs are...**\n",
    "\n",
    "1. Latent Dirichlet Allocation latent topic prediction model\n",
    "\n",
    "\n",
    "## Further Notes\n",
    "**During the project multiple models were evaluated. It was found that:**\n",
    "\n",
    "1. LDA was comparitively quick to train and returned excellent coherence scores (>0.5)\n",
    "2. Embeddings based methods returned too broad a range of topics to useful for human labelling\n",
    "\n",
    "**Future Improvements:**\n",
    "\n",
    "1. Spell check on the text inputs to improve the BOW representation\n",
    "2. Fine tune an embedding model (similar approach to what would be done for a transformer based sentiment model) and apply GenAI to automatically label the generated topics to remove the human labelling constraint"
   ]
  },
  {
   "cell_type": "code",
   "id": "57f87748-8473-4d93-96c0-f6dfcef8f0c8",
   "metadata": {
    "language": "python",
    "name": "cell47",
    "collapsed": false
   },
   "outputs": [],
   "source": "__name__ = '__main__'",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b7fc96ba-8aa5-406c-a69c-dd815be7725f",
   "metadata": {
    "name": "cell2"
   },
   "source": [
    "# 1 Package Imports and Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8ac2ba-d8ea-44ef-bcf7-31e88f4bdaab",
   "metadata": {
    "name": "cell3"
   },
   "source": [
    "## 1.0 Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac599b8-08bd-45f5-a839-8aaf6e430d43",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# snowflake functions\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "# Snowpark ML\n",
    "from snowflake.ml.registry import Registry\n",
    "from snowflake.ml._internal.utils import identifier\n",
    "\n",
    "# modelling and prep libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaMulticore, coherencemodel\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7368edf-a427-49ef-af57-47756e244db6",
   "metadata": {
    "collapsed": false,
    "name": "cell5"
   },
   "source": [
    "## 1.1 Notebook Constants"
   ]
  },
  {
   "cell_type": "code",
   "id": "c88eda5a-a80d-4ca2-a730-1a7b0e5c9b0a",
   "metadata": {
    "language": "python",
    "name": "cell43",
    "collapsed": false
   },
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\n\n# Set seed for reproducibility\nseed = 1234\nnp.random.seed(seed)\n\n# Define the columns as mentioned\nall_comment_cols = [\n    'comment_reponse', 'promoter_comment', 'passive_comment', 'detractor_comment', \n    'overall_experience_comment', 'admission_information_comment', 'went_well_improved_comment', \n    'staff_communication_comment', 'inclusion_support_perspn_comment', 'communication_and_treatment_comment', \n    'cultural_and_spiritual_needs_comment', 'included_in_decisions_comment', 'pain_relief_comment', \n    'worries_or_concerns_comment', 'meals_comment', 'cleanliness_comment', 'leaving_preparation_comment', \n    'medication_comment', 'anything_to_add'\n]\n\n# Generate sample data\nnum_samples = 500\n\ndata = {\n    'unique_id': np.arange(1, num_samples + 1),\n    'comment_reponse': np.random.choice(['Good service', 'Bad experience', 'Average care', None], num_samples),\n    'promoter_comment': np.random.choice(['Excellent staff', 'Very satisfied', 'Great environment', None], num_samples),\n    'passive_comment': np.random.choice(['It was okay', 'Nothing special', 'Neutral feelings', None], num_samples),\n    'detractor_comment': np.random.choice(['Terrible service', 'Very disappointed', 'Bad management', None], num_samples),\n    'overall_experience_comment': np.random.choice(['Wonderful stay', 'Could be better', 'Poor facilities', None], num_samples),\n    'admission_information_comment': np.random.choice(['Clear instructions', 'Confusing process', 'No information', None], num_samples),\n    'went_well_improved_comment': np.random.choice(['Food quality', 'Staff behavior', 'Cleanliness', None], num_samples),\n    'staff_communication_comment': np.random.choice(['Very informative', 'Lack of communication', 'Average', None], num_samples),\n    'inclusion_support_perspn_comment': np.random.choice(['Very supportive', 'Not inclusive', 'Okay', None], num_samples),\n    'communication_and_treatment_comment': np.random.choice(['Excellent treatment', 'Poor communication', 'Good but slow', None], num_samples),\n    'cultural_and_spiritual_needs_comment': np.random.choice(['Met all needs', 'Ignored needs', 'Neutral', None], num_samples),\n    'included_in_decisions_comment': np.random.choice(['Fully included', 'Excluded', 'Partially included', None], num_samples),\n    'pain_relief_comment': np.random.choice(['Effective', 'Ineffective', 'Average', None], num_samples),\n    'worries_or_concerns_comment': np.random.choice(['Addressed all concerns', 'Ignored concerns', 'Somewhat addressed', None], num_samples),\n    'meals_comment': np.random.choice(['Tasty meals', 'Bland food', 'Good variety', None], num_samples),\n    'cleanliness_comment': np.random.choice(['Very clean', 'Dirty', 'Acceptable', None], num_samples),\n    'leaving_preparation_comment': np.random.choice(['Well prepared', 'Unprepared', 'Average preparation', None], num_samples),\n    'medication_comment': np.random.choice(['On time', 'Late', 'No issues', None], num_samples),\n    'anything_to_add': np.random.choice(['Thank you', 'Never coming back', 'Great experience', None], num_samples)\n}\n\n# Create DataFrame\ndf_raw = pd.DataFrame(data)\n\n# Display the DataFrame\ndf_raw.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "940b3d1a-d473-44c9-adc0-294c2c4b2fb6",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell6",
    "collapsed": false
   },
   "outputs": [],
   "source": "# set seed for reproducible results\nseed = 1234\nnp.random.seed(seed)\n\n# whether to evaluate the hyperparameter n_topics. Setting True will run the final section. \n# This is only necessary when you want to re-evaluate the number of topics LDA will fit\nevaluate_num_topics = False\n\n\n# col name grouping for easy filtering\nall_comment_cols = ['comment_reponse','promoter_comment','passive_comment','detractor_comment','overall_experience_comment','admission_information_comment',\n                   'went_well_improved_comment','staff_communication_comment', 'inclusion_support_perspn_comment', 'communication_and_treatment_comment',\n                   'cultural_and_spiritual_needs_comment','included_in_decisions_comment','pain_relief_comment','worries_or_concerns_comment',\n                    'meals_comment', 'cleanliness_comment','leaving_preparation_comment','medication_comment','anything_to_add']"
  },
  {
   "cell_type": "markdown",
   "id": "36e7aa43-c527-437a-8ad3-285a69ccf418",
   "metadata": {
    "collapsed": false,
    "name": "cell7"
   },
   "source": [
    "## 1.2 Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a073f05f-3215-489f-8019-c0600e892065",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell28",
    "collapsed": false
   },
   "outputs": [],
   "source": "session = get_active_session()\n\n## Define the SQL query\n#query = \"select top 500 * from dw.public.hospital_reviews\" # TODO: remove 500 row limit once notebook is running\nquery = \"select top 500 * from demo_datasets.public.hospital_reviews\"\n## Execute the query and fetch the data into a Pandas DataFrame\ndf_raw = session.sql(query).to_pandas()\n#\n## Display the DataFrame\ndf_raw.head()"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68fce82-8225-4e12-96f6-664cb53c236d",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell8",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change all cols to lower case. Personal preference but makes writting out col headers faster\n",
    "df_raw.columns = df_raw.columns.str.lower()\n",
    "\n",
    "# rename the id key to match existing processing pipelines from the project created prior to the adding of a unique_id to the dataset\n",
    "df_raw = df_raw.rename(columns={'unique_id': 'surrogate_survey_id'})\n",
    "\n",
    "# create a seperate copy to compare to raw if necessary\n",
    "df_imported = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86209623-558a-4cf9-b259-73edae2b6a11",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell32",
    "collapsed": false
   },
   "outputs": [],
   "source": "\n# spacy's language model...\nnlp = spacy.load(\"en_core_web_sm\")\n# nltk's part-of-speech tagger\n# NB: if other nltk components are required, download them from github and \n# upload them to the appropruate sub folder of the nltk_data folder next to this notebook\n# more details can be found here: https://www.nltk.org/data.html\n\nif 'nltk_data' not in nltk.data.path:\n    nltk.data.path.append('nltk_data')"
  },
  {
   "cell_type": "markdown",
   "id": "478d36ea-5e5a-430f-b325-c442f4879e54",
   "metadata": {
    "collapsed": false,
    "name": "cell9"
   },
   "source": [
    "# 2 Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93b2f91-9709-4a95-8025-2b246be48780",
   "metadata": {
    "collapsed": false,
    "name": "cell10"
   },
   "source": [
    "## 2.0 Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c350c7-8fa5-4fac-94ca-5cd6b6721bbd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "name": "cell11"
   },
   "source": [
    "**Tidy format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38dec37-4da1-47dc-827c-8f4d0d8b33c0",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell29",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# added line breaks to deal with the line limit\n",
    "stop_word_list = ['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'around', 'as', 'at', \n",
    "                 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both', 'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'computer', 'con', 'could', 'couldnt', 'cry', \n",
    "                 'de', 'describe', 'detail', 'did', 'didn', 'do', 'does', 'doesn', 'doing', 'don', 'done', 'down', 'due', 'during', 'each', 'eg', 'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'except', \n",
    "                 'few', 'fifteen', 'fify', 'fill', 'find', 'fire', 'first', 'five', 'for', 'former', 'formerly', 'forty', 'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', \n",
    "                 'i', 'ie', 'if', 'in', 'inc', 'indeed', 'interest', 'into', 'is', 'it', 'its', 'itself', 'just', 'keep', 'kg', 'km', 'last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made', 'make', 'many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine', 'more', 'moreover', 'most', 'mostly', 'move', 'much', 'must', 'my', 'myself', \n",
    "                 'name', 'namely', 'neither', 'never', 'nevertheless', 'next', 'nine', 'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of', 'off', 'often', 'on', 'once', 'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'part', 'per', 'perhaps', 'please', 'put', 'quite', \n",
    "                 'rather', 'rather', 're', 'really', 'regarding', 'same', 'say', 'see', 'seem', 'seemed', 'seeming', 'seems', 'serious', 'several', 'she', 'should', 'show', 'side', 'since', 'sincere', 'six', 'sixty', 'so', 'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'system', \n",
    "                 'take', 'ten', 'than', 'that', 'the', 'their', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thick', 'thin', 'third', 'this', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward', 'towards', 'twelve', 'twenty', 'two', \n",
    "                 'un', 'under', 'unless', 'until', 'up', 'upon', 'us', 'used', 'using', 'various', 'very', 'very', 'via', \n",
    "                 'was', 'we', 'well', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves']\n",
    "\n",
    "# If a single line gets too long Snowflake (streamlit) silently fails to populate the list\n",
    "# The stop word list must not be empty or the notebook will fail\n",
    "stop_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34655cde-d39a-4bfb-8f09-bbfeb6a1ed74",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell30",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocessing functions. TODO once stage_packages are available in Snowflake AU use that to load the preprocessing .py scripts provided\n",
    "# that way any edits to preprocessing are done in one place vs updating each notebook that contains the following code\n",
    "\n",
    "def get_clean_text(df, col_name):\n",
    "    \"\"\"\n",
    "    Parent function to call all related functions to prepare text for modelling.\n",
    "    :param df: dataframe with customer comments to clean\n",
    "    :param col: column name in dataframe containing comments\n",
    "    :param encode_ascii: whether to remove non-ascii characters from comments\n",
    "    :param lowercase: whether to convert all comments to lower case. If applying VADER set this to False\n",
    "    :param lemmas: whether to convert matching words to spacy lemmas\n",
    "    :param remove_punc: whether to remove punctuation\n",
    "\n",
    "    :return: dataframe with comments column cleaned as per spec\n",
    "    \"\"\"\n",
    "\n",
    "    # remove non-taggable tokens/characters i.e. emojis\n",
    "    df.loc[:, col_name] = df[col_name].map(drop_non_ascii)\n",
    "\n",
    "    # lowercase texts\n",
    "    df.loc[:, col_name] = df[col_name].map(lambda x: x.lower())\n",
    "\n",
    "    # lemmatize words\n",
    "    df.loc[:, col_name] = df[col_name].astype(str).map(lemma)\n",
    "\n",
    "    # remove punctuation\n",
    "    df.loc[:, col_name] = df[col_name].map(drop_punctuation)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_non_ascii(comment):\n",
    "    \"\"\"\n",
    "    Removes non ascii characters from comments i.e. emojis\n",
    "    If applying VADER retain emojis\n",
    "    :param comment: a comment\n",
    "    :return: comment with only ascii characters\n",
    "    \"\"\"\n",
    "    comment = comment.encode('ascii', errors = 'ignore')\n",
    "    return comment\n",
    "\n",
    "def lemma(comment):\n",
    "    \"\"\"\n",
    "    Lemmatize comments using spacy lemmatizer.\n",
    "    :param comment: a comment\n",
    "    :return: lemmatized comment\n",
    "    \"\"\"\n",
    "    lemmatized = nlp(comment)\n",
    "    lemmatized_final = ' '.join([word.lemma_ for word in lemmatized if word.lemma_ != '\\'s'])\n",
    "    return lemmatized_final\n",
    "\n",
    "\n",
    "def drop_punctuation(comment):\n",
    "    \"\"\"\n",
    "    Removes punctuation characters from comments\n",
    "    If applying VADER retain punctuation\n",
    "    :param comment: a comment\n",
    "    :return: comment without punctuations\n",
    "    \"\"\"\n",
    "    regex = re.compile('[' + re.escape('!\"#%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~')+'0-9\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", comment)\n",
    "    nopunct_words = nopunct.split(' ')\n",
    "    filter_words = [word.strip() for word in nopunct_words if word != '']\n",
    "    words = ' '.join(filter_words)\n",
    "    return words\n",
    "\n",
    "def get_tidy_text(df, col_names_to_keep, id_col_name):\n",
    "    \"\"\"\n",
    "    Takes a wide form dataframe and converts it to long form (tidy format)\n",
    "    Also extends features and applies a standard set of quality control rules\n",
    "\n",
    "    :param df: dataframe to restructure\n",
    "    :param col_names_to_keep: comment columns of df to keep\n",
    "    :param id_col_name: column of df that holds the unique survey id\n",
    "    :return: tidy dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # reduce to desired cols\n",
    "    df_new = df[col_names_to_keep]\n",
    "\n",
    "    # pivot to long form and order by survey (default order is column_header)\n",
    "    df_new = pd.melt(df_new, id_vars=[id_col_name], var_name='comment_header', value_name='comment_response')\n",
    "\n",
    "    # sort to keep all comments for a survey together when viewing the dataframe\n",
    "    df_new = df_new.sort_values(by=id_col_name, ascending=True)\n",
    "\n",
    "    # get count of populated comments before applying quality control\n",
    "    initial_comment_count = df_new.dropna().shape[0]\n",
    "\n",
    "    # extend features\n",
    "    df_new['word_count'] = df_new['comment_response'].apply(count_words)\n",
    "\n",
    "    # apply quality control rules\n",
    "\n",
    "    # drop rows (comments) with fewer than 3 words\n",
    "    df_new = df_new.dropna(subset=['comment_response']).loc[df_new['word_count'] >= 3]\n",
    "\n",
    "    final_survey_count = len(df_new['surrogate_survey_id'].unique())\n",
    "    \n",
    "    print('Started with {} surveys and {} comments. \\n '\n",
    "          'Left with {} surveys and {} comments after quality control.'.format(df.shape[0],\n",
    "                                                                               initial_comment_count,\n",
    "                                                                               final_survey_count,\n",
    "                                                                               df_new.shape[0]))\n",
    "\n",
    "    return df_new\n",
    "\n",
    "\n",
    "def count_words(text):\n",
    "    \"\"\"\n",
    "    Simple function to count words based on spaces.\n",
    "    :param text: text to count words in\n",
    "    :return: integer of words in text\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return len(text.split())\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "def tokenize_comments(df, col_name, keep_verbs=False, min_comment_length=2):\n",
    "    \"\"\"\n",
    "    Processes a column of comments from a dataframe to prepare for LDA.\n",
    "    Assumes the comments have already been cleaned by get_clean_text\n",
    "    :param df: dataframe of comments\n",
    "    :param col_name: column of the dataframe that contains the cleaned survey comments\n",
    "    :param keep_verbs: if True include nouns AND verbs. If False keep only nouns. Default is False\n",
    "    :param min_comment_length: comments with fewer words than this will be dropped. Defailt is 2\n",
    "    :return: dataframe with comments formatted as a list of processed n_grams\n",
    "    \"\"\"\n",
    "\n",
    "    print(df.shape)\n",
    "    # drop stop words and erroneous small words/typos\n",
    "    df_new = df[col_name].map(lambda x: [word for word in x.split() \\\n",
    "                                            if word not in stop_word_list\\\n",
    "                                                and len(word) > 2])\n",
    "\n",
    "    # filter for the desired part-of-speech tags (nouns only or nouns+verbs)\n",
    "    df_new = df_new.apply(filter_by_pos_tags, keep_verbs=keep_verbs)\n",
    "\n",
    "    # filter to comments at or above a minimum length\n",
    "    df_new = df_new[df_new.apply(lambda x: len(x) >= min_comment_length)]\n",
    "\n",
    "    return df_new\n",
    "\n",
    "\n",
    "def filter_by_pos_tags(df, keep_verbs=False):\n",
    "    \"\"\"\n",
    "    Parses and applies part-of-speech tags to comments. Comments are then filtered to nouns and (optionally) verbs.\n",
    "    Nouns are more indicative of topics thus this filtering improves topic interpretability.\n",
    "    :param df: dataframe of comments (only) to parse\n",
    "    :param keep_verbs: if True include nouns AND verbs. If False keep only nouns. Default is False\n",
    "    :return: list of filtered comments\n",
    "    \"\"\"\n",
    "    pos_comment = nltk.pos_tag(df)\n",
    "\n",
    "    if keep_verbs:\n",
    "        # keep nouns and verbs\n",
    "        filtered_list = [word[0] for word in pos_comment if word[1] in ['NN','VB', 'VBD', 'VBG', 'VBN', 'VBZ']]\n",
    "    else:\n",
    "        # keep nouns only\n",
    "        filtered_list = [word[0] for word in pos_comment if word[1] in ['NN']]\n",
    "    return filtered_list\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "8b2f04b5-2c21-41c4-b9da-526f4447f24b",
   "metadata": {
    "language": "python",
    "name": "cell23",
    "collapsed": false
   },
   "outputs": [],
   "source": "df_imported = df_raw",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0031fb8-1a05-4747-9d84-d7edacc8bdbc",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell12",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started with 29884 surveys and 84732 comments. \n",
      " Left with 25443 surveys and 74470 comments after quality control.\n"
     ]
    }
   ],
   "source": [
    "cols_to_include = all_comment_cols + ['surrogate_survey_id']\n",
    "\n",
    "stacked_df = get_tidy_text(df_imported, cols_to_include, 'surrogate_survey_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22305d40-8292-479a-9f80-60604da1c751",
   "metadata": {
    "collapsed": false,
    "name": "cell13"
   },
   "source": [
    "**Clean text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "352da77e-853a-4ce5-812e-7664814ca61e",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OEM\\Dropbox\\Contracting\\FIRN\\SCHL\\schl_aa_tidy_text.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col_name] = df[col_name].map(drop_non_ascii)\n",
      "C:\\Users\\OEM\\Dropbox\\Contracting\\FIRN\\SCHL\\schl_aa_tidy_text.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col_name] = df[col_name].map(lambda x: x.lower())\n",
      "C:\\Users\\OEM\\Dropbox\\Contracting\\FIRN\\SCHL\\schl_aa_tidy_text.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col_name] = df[col_name].astype(str).map(lemma)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 455.4314966201782 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OEM\\Dropbox\\Contracting\\FIRN\\SCHL\\schl_aa_tidy_text.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col_name] = df[col_name].map(drop_punctuation)\n"
     ]
    }
   ],
   "source": [
    "# takes ~8min\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clean_comments_df = get_clean_text(stacked_df[['comment_response']], 'comment_response')\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken: {} seconds\".format(end_time - start_time))\n",
    "\n",
    "\n",
    "final_comments= tokenize_comments(df=clean_comments_df, \n",
    "                                   col_name='comment_response',\n",
    "                                   keep_verbs=False,\n",
    "                                   min_comment_length=2)\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2b1d02-1788-469c-90b6-cb11838be23b",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell31"
   },
   "outputs": [],
   "source": [
    "# check the tokenization has worked\n",
    "final_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c17bc3-fa71-4643-b132-5626edc61462",
   "metadata": {
    "collapsed": false,
    "name": "cell15"
   },
   "source": [
    "**Tokenize and Filter Comments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74220ae3-2719-4143-a5a4-3b700be7a01b",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 89.71900153160095 seconds\n"
     ]
    }
   ],
   "source": [
    "# takes ~1.5min\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "final_comments= tokenize_comments(df=clean_comments_df,\n",
    "                                   col_name='comment_response',\n",
    "                                   keep_verbs=False,\n",
    "                                   min_comment_length=2)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken: {} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a92de4-6c21-4f51-a478-2321251b08a9",
   "metadata": {
    "collapsed": false,
    "name": "cell17"
   },
   "source": [
    "**Generate Dictionary and Document Term Matrix for Model Fitting**\n",
    "\n",
    "The dictionary maps each token (word) to a numeric ID. The document term matrix maps each token within a comment to its ID in the dictionary\n",
    "Both objects are required for model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b70cfdaa-101f-4131-8f5c-ddc2b777115e",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell18"
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(final_comments)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in final_comments]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177bd329-4515-4b05-8396-70114312ed7d",
   "metadata": {
    "collapsed": false,
    "name": "cell19"
   },
   "source": [
    "## 2.1 Fit a 10 Topic Model\n",
    "\n",
    "The number if topics is a critical hyperparameter in LDA. Experimentation suggested a good coherence was reached at 10 topics. The best coherence was at around 18-22 topics but FIRN decided that was too many to be interpretable initially. Once SCHL is comfortable with the output of topic models, FIRN strongly recommends increasing the num_topics to at least 18 to get a more granular view of latent themes in the customer comments.\n",
    "\n",
    "\n",
    "In section 2.2 there is code to evaluate a range of values of num_topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "090a979b-696b-4820-8d74-d97b7bde9b31",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": [
    "ldamodel = LdaMulticore(doc_term_matrix, \n",
    "               num_topics=10, # 10 was found to be a good balance of coherence, diversity and quality (~0.6 c_v coherence)\n",
    "               id2word = dictionary, \n",
    "               passes=40, # adjust this down to speed up fitting\n",
    "               iterations=200, # adjust this down to speed up fitting\n",
    "               chunksize = 10000, # adjust this down if the environment hits memory issues. Training will be slower.\n",
    "               eval_every = None, # this uses perplexity but we want to use coherence. However, dropping this hyperparameter may improve a model.\n",
    "               random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3983812-fb6a-49f7-be5e-107e39a46bfc",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell35"
   },
   "outputs": [],
   "source": [
    "# measure the coherence of the topics. \n",
    "cm = coherencemodel.CoherenceModel(model=ldamodel, texts=final_comments,\n",
    "                                                         dictionary=dictionary, coherence='c_v')\n",
    "c_v_coherence = cm.get_coherence()\n",
    "c_v_coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c4bac7-d26e-4e49-a17b-6ba3d2f952fd",
   "metadata": {
    "collapsed": false,
    "name": "cell21"
   },
   "source": [
    "**Save the Model**\n",
    "\n",
    "This also saves the objects related to the model - dictionary, model state and some precompted topic distribution values (the file ending with ...expElogbeta.npy).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eda4bd-6bb0-455f-90a5-eba7e3154410",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "cell25"
   },
   "outputs": [],
   "source": [
    "-- here is another way to define the database and schema for the model registry.  \n",
    "-- \"Another way\" means an SQL alternative to the python code version in the train sentiment model notebook \n",
    "use database SCHL_DEV;\n",
    "create schema if not exists ML_MODEL_REGISTRY;\n",
    "use schema ML_MODEL_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72180ca0-b46b-4072-9d21-146ee5fe3db0",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell33"
   },
   "outputs": [],
   "source": [
    "# function to find the current model version and return the next version to use\n",
    "def get_next_model_version(reg, model_name):\n",
    "    models = reg.show_models()\n",
    "    if models.empty:\n",
    "        return 'V_1'\n",
    "    elif model_name not in models['name'].to_list():\n",
    "        return 'V_1'\n",
    "    max_version = max(\n",
    "        ast.literal_eval(models.loc[models['name'] == model_name, 'versions'].values[0])\n",
    "    )\n",
    "    return 'V_{}'.format({int(max_version.split('_')[-1]) + 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b610b7-01ff-4721-a7bc-4849d31b5aea",
   "metadata": {
    "collapsed": false,
    "name": "save_model"
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab36d9-311e-467c-9fe3-d3eb1ac65783",
   "metadata": {
    "collapsed": false,
    "name": "cell38"
   },
   "source": [
    "## Option 1: Save the model artifacts to a stage\n",
    "\n",
    "This code is not required if using the registry. However, it is here if you need a way to save the model objects somewhere else so you can download them and use them against a notebook (or an environment outside snowflake)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462884b1-a38f-4ba1-a13e-a610a61b331a",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell27"
   },
   "outputs": [],
   "source": [
    "# how to \"put\" files in snowflake \n",
    "\n",
    "\n",
    "model_name = \"CEMPLICITY_TOPIC_MODEL\"\n",
    "\n",
    "# get current db and schema to create the registry against\n",
    "\n",
    "db = identifier._get_unescaped_name(session.get_current_database())\n",
    "schema = identifier._get_unescaped_name(session.get_current_schema())\n",
    "\n",
    "# Create a model registry\n",
    "reg = Registry(session=session, database_name=db, schema_name=schema) # TODO: change this to just session=session once target db and schema are defined\n",
    "\n",
    "\n",
    "next_model_version = get_next_model_version(reg, model_name) # this will always return V_1 while the model registry is not being used by this model\n",
    "\n",
    "# save the file to the temporary local file storage associated with the notebook session. !!This will not persist across sessions\n",
    "ldamodel.save('{}_{}'.format(model_name, next_model_version))\n",
    "\n",
    "print('The next version of the model {} is: {}'.format(model_name, next_model_version))\n",
    "\n",
    "\n",
    "# now push the files to a permenant stage\n",
    "put_result_model = session.file.put('{}_{}'.format(model_name, next_model_version),'@TEST', auto_compress = False, overwrite=True)\n",
    "put_result_id2word = session.file.put('{}_{}.id2word'.format(model_name, next_model_version),'@TEST', auto_compress = False, overwrite=True)\n",
    "put_result_state = session.file.put('{}_{}.state'.format(model_name, next_model_version),'@TEST', auto_compress = False, overwrite=True)\n",
    "put_result_betas = session.file.put('{}_{}.expElogbeta.npy'.format(model_name, next_model_version),'@TEST', auto_compress = False, overwrite=True)\n",
    "\n",
    "print('\\n model: {}\\n id2word: {}\\n state: {}\\n betas: {}'.format(put_result_model[0].status,\n",
    "                                                              put_result_id2word[0].status,\n",
    "                                                              put_result_state[0].status,\n",
    "                                                              put_result_betas[0].status))\n",
    "# UPLOADED means saved, SKIPPED means the file already exists. The put is set to overwrite so we should always see UPLOADED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6656af16-03e8-4c57-beaf-1a970220d837",
   "metadata": {
    "collapsed": false,
    "name": "cell37"
   },
   "source": [
    "## Option 2: Save the model to the Snowflake Registry\n",
    "\n",
    "Requires a custom model to log the LDA model to a snowflake model registry. Gensim models are not currently supported by Snowflake\n",
    "\n",
    "!!This will not work as snowflake's conversion of the custom model class to a UDF triggers a max recursion issue with Pickle. Increasing the max recursion limit causes the notebook to crash. This code is kept here for when snowflake resolve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf63b51-b056-4ecd-9c37-c76781829714",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell24"
   },
   "outputs": [],
   "source": [
    "# required packages\n",
    "from snowflake.ml.model import custom_model\n",
    "from snowflake.ml.model import model_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa07adbf-83f1-4fe0-8541-36065b4c3d20",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "cell44"
   },
   "outputs": [],
   "source": [
    "-- Push the files to a permenant stage so they persist and can be called from any notebook\n",
    "use database SCHL_DEV;\n",
    "use schema ML_MODEL_REGISTRY;\n",
    "\n",
    "create stage if not exists test; --TODO: needs to be somewhere more permenant once determined by SCHL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e48fe2-c305-486c-aa2a-73d330d10454",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell39"
   },
   "outputs": [],
   "source": [
    "# TODO: can delete the test stage on the ML registry schema and this code once the notebook runs and log_model() executes successfully.\n",
    "\n",
    "model_name = \"CEMPLICITY_TOPIC_MODEL\"\n",
    "\n",
    "# get current db and schema to create the registry against\n",
    "\n",
    "db = identifier._get_unescaped_name(session.get_current_database())\n",
    "schema = identifier._get_unescaped_name(session.get_current_schema())\n",
    "\n",
    "# Create a model registry\n",
    "reg = Registry(session=session, database_name=db, schema_name=schema) # TODO: change this to just session=session once target db and schema are defined\n",
    "\n",
    "next_model_version = get_next_model_version(reg, model_name)\n",
    "\n",
    "# save the file to the temporary local file storage associated with the notebook session. !!This will not persist across sessions\n",
    "ldamodel.save('{}_{}'.format(model_name, next_model_version))\n",
    "\n",
    "print('The next version of the model {} is: {}'.format(model_name, next_model_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a415589-f2fa-4f27-8bfc-22ff01421238",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell40"
   },
   "outputs": [],
   "source": "# create custom class for Gensim LDA models. Any such model can use this class.\n\nclass custom_lda_model(custom_model.CustomModel):\n    def __init__(self, context: custom_model.ModelContext) -> None:\n        super().__init__(context)\n\n        # model\n        model_dir = self.context.path('model_file')\n        self.model = LdaMulticore.load(model_dir)\n\n        # load the mapping of words to IDs\n        id2word_dir = self.context.path('id2word')\n        self.id2word = corpora.Dictionary.load(id2word_dir) # to get around a picking recursion error\n\n    # define the predict method\n    @custom_model.inference_api\n    def predict(self, input: pd.DataFrame) -> pd.DataFrame:\n       \n        # extract the text feature as a series as the bag of words method does not accept a dataframe\n        comments = input.iloc[:,0]\n\n        # create the matrix of documents the terms (words) within them\n        doc_term_matrix = [self.id2word.doc2bow(doc) for doc in comments]\n \n        #for each document get the topic with the highest attribution.\n        print('preparing predictions for model: {} on samples of len: {}'.format(self.model,len(doc_term_matrix)))\n        preds = [self.model.get_document_topics(doc) for doc in doc_term_matrix] # attribution per topic for all topics per doc\n        top_topics = [max(doc, key=lambda x: x[1])[0] for doc in preds] # topic with the highest attribution per doc\n        attributions = [max(doc, key=lambda x: x[1])[1] for doc in preds] # value of the highest attribution per doc\n        \n        model_output = pd.DataFrame({\n            'predicted_topic': top_topics,\n            '__name__ = '__main__'': attributions\n        }) \n    \n        return model_output"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d05b3e-7eea-4e58-b611-cb696ec05a91",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell46"
   },
   "outputs": [],
   "source": [
    "# specify the location of the model artifacts which are those saved locally to this notebook session. \n",
    "\n",
    "lda_mc2 = custom_model.ModelContext(\n",
    "    artifacts={\n",
    "        'model_file': 'CEMPLICITY_TOPIC_MODEL_V_1',\n",
    "        'expElogbeta': 'CEMPLICITY_TOPIC_MODEL_V_1.expElogbeta.npy',\n",
    "        'id2word': 'CEMPLICITY_TOPIC_MODEL_V_1.id2word',\n",
    "        'state':'CEMPLICITY_TOPIC_MODEL_V_1.state'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863ed85-a3b0-4c13-8c5f-d004e2f16e44",
   "metadata": {
    "collapsed": false,
    "name": "cell41"
   },
   "source": [
    "**Verify the custom model works**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c77d21-7a2d-48cf-a51c-c128989325ab",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell36"
   },
   "outputs": [],
   "source": [
    "# sample of data\n",
    "data_sample = pd.DataFrame(final_comments[:5])\n",
    "\n",
    "# load the custom model via the custom class created above\n",
    "my_lda_model = custom_lda_model(lda_mc2)\n",
    "\n",
    "# run inference\n",
    "output_data = my_lda_model.predict(data_sample)\n",
    "output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194bb9f5-9834-4e77-beff-56d354b65b21",
   "metadata": {
    "collapsed": false,
    "name": "cell22"
   },
   "source": [
    "**Location of the error when trying to log the custom model class** \n",
    "\n",
    "log_model() fails with the error: \"PicklingError: Could not pickle object as excessively deep recursion required\"\n",
    "\n",
    "tried:\n",
    "1. increasing the recursion limit with sys.setrecursionlimit. W/H fails at around 30k which is still too small for the log_model method to work\n",
    "2. setting the resource rstack limit\n",
    "3. vectorizing the for loop in the model class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b3d0a7-5fe5-4184-8d29-159a2c172d24",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell34"
   },
   "outputs": [],
   "source": [
    "# Log the model\n",
    "# the name + version must be unique and both are strings. The name could be a UUID but a short description of the use case is more practical.\n",
    "# the model can be logged with metrics, to track history, and the features\n",
    "\n",
    "# use the sample data and inference result to infer the signature (col names and types)\n",
    "inferred_signature = model_signature.infer_signature(input_data=data_sample, output_data=output_data)\n",
    "\n",
    "logged_model = reg.log_model(\n",
    "        model = my_lda_model,\n",
    "        model_name = model_name,\n",
    "        version_name = get_next_model_version(reg, model_name), # assumes versioning is incremental\n",
    "        metrics = {'c_v_coherence': c_v_coherence},\n",
    "        signatures={\"predict\": inferred_signature},\n",
    "        options={\"relax_version\": False},\n",
    "        comment = 'This is the topic model trained on the Cemplicity survey data.'\n",
    ")\n",
    "\n",
    "# bug with comments not saving when submitted by log_model. TODO: retest as this seems to have been resolved by the time we did the sentiment model\n",
    "#logged_model.comment = 'This is the topic model trained on the Cemplicity survey data.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd40619-6c86-470b-bbeb-1e330102b2be",
   "metadata": {
    "collapsed": false,
    "name": "cell42"
   },
   "source": [
    "# Explore The Optimum Value for num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e43e5b8-e6df-4862-9b0e-b086c79d68dd",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell26"
   },
   "outputs": [],
   "source": [
    "# takes 60+ min to run on a local PC as it's building a topic model for every number between 5 and 25.\n",
    "\n",
    "\n",
    "if evaluate_num_topics:\n",
    "    \n",
    "    counter = 1\n",
    "    \n",
    "    for i in [1,2,3]:\n",
    "        start_time = time.time()\n",
    "        print('evaluating min doc length of {}'.format(counter))\n",
    "\n",
    "        # these are only necessary if inspecting variance in attribution between models across topics and terms \n",
    "        # this may cause memory problems in snowflake\n",
    "        #dictionary = dictionaries['dictionary{}'.format(counter)]\n",
    "        #doc_term_matrix = doc_term_matrices['doc_term_matrix{}'.format(counter)]\n",
    "        \n",
    "        coherence = []\n",
    "        for k in range(5,25):\n",
    "            print('Round: '+str(k))\n",
    "            ldamodel = LdaMulticore(doc_term_matrix, num_topics=k, id2word = dictionary, passes=40, workers=7, # set this equal to the number of PHYSICAL cores\n",
    "                           iterations=200, chunksize = 10000, eval_every = None)\n",
    "            \n",
    "            cm = coherencemodel.CoherenceModel(model=ldamodel, texts=final_reviews,\n",
    "                                                             dictionary=dictionary, coherence='c_v')\n",
    "            coherence.append((k,cm.get_coherence()))\n",
    "    \n",
    "        end_time = time.time()\n",
    "        print(\"Time taken: {} seconds\".format(end_time - start_time))\n",
    "        \n",
    "        \n",
    "        x_val = [x[0] for x in coherence]\n",
    "        y_val = [x[1] for x in coherence]\n",
    "        \n",
    "        print('\\n\\nPlot for min doc length of {}'.format(counter))\n",
    "        plt.plot(x_val,y_val)\n",
    "        plt.scatter(x_val,y_val)\n",
    "        plt.title('Number of Topics vs. Coherence')\n",
    "        plt.xlabel('Number of Topics')\n",
    "        plt.ylabel('Coherence')\n",
    "        plt.xticks(x_val)\n",
    "        plt.show()\n",
    "        counter += 1"
   ]
  }
 ]
}